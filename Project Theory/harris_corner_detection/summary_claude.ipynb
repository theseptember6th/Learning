{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge and Corner Detection in Computer Vision\n",
    "\n",
    "## 1. Introduction to Feature Detection\n",
    "\n",
    "In computer vision, **feature detection** refers to identifying key points or regions in an image that contain significant information. The most common features include edges, corners, and blobs. These features serve as the foundation for higher-level tasks such as object recognition, image matching, and visual tracking.\n",
    "\n",
    "## 2. Edge Detection\n",
    "\n",
    "### 2.1 What is an Edge?\n",
    "\n",
    "An **edge** is a region in an image where the pixel intensity changes abruptly. Edges typically represent boundaries between different objects or surfaces in an image. They are fundamental features that help in understanding the structure of an image.\n",
    "\n",
    "Edges can be caused by:\n",
    "- Changes in color or texture\n",
    "- Changes in surface orientation\n",
    "- Variations in scene depth\n",
    "- Changes in material properties\n",
    "- Lighting conditions (shadows, highlights)\n",
    "\n",
    "### 2.2 Types of Edges\n",
    "\n",
    "Edges can be classified based on their intensity profiles:\n",
    "\n",
    "1. **Step Edge**: A sudden change in intensity (like a black-white boundary)\n",
    "2. **Ramp Edge**: A gradual change in intensity over a small distance (common in real images)\n",
    "3. **Roof Edge**: A sharp peak in intensity (like a sharp fold in paper)\n",
    "4. **Line Edge**: A thin, high-intensity feature surrounded by lower-intensity regions\n",
    "\n",
    "### 2.3 Edge Detection Methods\n",
    "\n",
    "Edge detection algorithms work by identifying pixels where the image gradient (rate of intensity change) is high. Common methods include:\n",
    "\n",
    "1. **Gradient-Based Methods**: Calculate the first derivative of the image intensity.\n",
    "   - **Sobel Operator**: Uses two 3×3 kernels to compute horizontal and vertical gradients\n",
    "   - **Prewitt Operator**: Similar to Sobel but with different kernel values\n",
    "   - **Roberts Cross Operator**: Uses 2×2 kernels for diagonal gradients\n",
    "\n",
    "2. **Second Derivative Methods**: Locate edges by finding zero-crossings.\n",
    "   - **Laplacian Operator**: Computes the second derivative of the image\n",
    "   - **Laplacian of Gaussian (LoG)**: Applies Gaussian smoothing before the Laplacian\n",
    "   - **Difference of Gaussians (DoG)**: Approximates the LoG\n",
    "\n",
    "3. **Advanced Techniques**:\n",
    "   - **Canny Edge Detector**: A multi-stage algorithm that reduces noise, finds gradients, applies non-maximum suppression, and uses hysteresis thresholding\n",
    "\n",
    "### 2.4 Mathematical Representation of Edge Detection\n",
    "\n",
    "The gradient magnitude and direction at each pixel are calculated as:\n",
    "\n",
    "$$\\text{Magnitude} = \\sqrt{G_x^2 + G_y^2}$$\n",
    "$$\\text{Direction} = \\tan^{-1}\\left(\\frac{G_y}{G_x}\\right)$$\n",
    "\n",
    "Where $G_x$ and $G_y$ are the gradients in the x and y directions, typically computed using convolution with specific kernels.\n",
    "\n",
    "## 3. Corner Detection\n",
    "\n",
    "### 3.1 What is a Corner?\n",
    "\n",
    "A **corner** is a point where two or more edges meet, resulting in intensity changes in multiple directions. Unlike edges (which have intensity changes in one primary direction), corners exhibit significant intensity variations in at least two directions.\n",
    "\n",
    "Corners are valuable features because they:\n",
    "- Are more stable than edges\n",
    "- Provide more distinctive information \n",
    "- Are invariant to rotation\n",
    "- Are useful for image matching and tracking\n",
    "\n",
    "### 3.2 The Concept of Corner Detection\n",
    "\n",
    "Corner detection algorithms analyze local neighborhoods around each pixel to determine if they represent a corner. The key idea is to examine how the image intensity changes when moving in different directions.\n",
    "\n",
    "## 4. Harris Corner Detection\n",
    "\n",
    "### 4.1 Basic Principle\n",
    "\n",
    "The Harris Corner Detection algorithm, proposed by Chris Harris and Mike Stephens in 1988, is based on the observation that at a corner, the image intensity changes significantly in multiple directions.\n",
    "\n",
    "### 4.2 Window Shifting\n",
    "\n",
    "The core concept of Harris Corner Detection is analyzing how a small window (patch) of pixels changes when shifted slightly in different directions:\n",
    "\n",
    "- **Flat Region**: When the window is shifted in any direction, there is minimal change in intensity\n",
    "- **Edge**: When shifted along the edge, there is minimal change; when shifted perpendicular to the edge, there is significant change\n",
    "- **Corner**: When shifted in any direction, there is significant change\n",
    "\n",
    "### 4.3 Mathematical Formulation\n",
    "\n",
    "For a small window shift (u, v), the intensity change is given by:\n",
    "\n",
    "$$E(u, v) = \\sum_{x,y} w(x,y) [I(x+u, y+v) - I(x,y)]^2$$\n",
    "\n",
    "Where:\n",
    "- $I(x,y)$ is the image intensity at position (x,y)\n",
    "- $w(x,y)$ is a weighting function (typically a Gaussian window)\n",
    "- The sum is over all pixels in the window\n",
    "\n",
    "### 4.4 Taylor Series Approximation\n",
    "\n",
    "Using Taylor series expansion, we can approximate:\n",
    "\n",
    "$$I(x+u, y+v) \\approx I(x,y) + u \\frac{\\partial I}{\\partial x} + v \\frac{\\partial I}{\\partial y}$$\n",
    "\n",
    "Which leads to:\n",
    "\n",
    "$$E(u, v) \\approx \\sum_{x,y} w(x,y) [u I_x + v I_y]^2$$\n",
    "\n",
    "Where $I_x$ and $I_y$ are the partial derivatives of the image.\n",
    "\n",
    "This can be rewritten in matrix form:\n",
    "\n",
    "$$E(u, v) \\approx \\begin{bmatrix} u & v \\end{bmatrix} M \\begin{bmatrix} u \\\\ v \\end{bmatrix}$$\n",
    "\n",
    "Where M is the structure tensor (also called the Harris matrix):\n",
    "\n",
    "$$M = \\sum_{x,y} w(x,y) \\begin{bmatrix} I_x^2 & I_x I_y \\\\ I_x I_y & I_y^2 \\end{bmatrix}$$\n",
    "\n",
    "### 4.5 Eigenvalue Analysis\n",
    "\n",
    "The eigenvalues ($\\lambda_1$ and $\\lambda_2$) of matrix M provide crucial information about the local structure:\n",
    "\n",
    "1. **Flat Region**: Both eigenvalues are small ($\\lambda_1 \\approx 0$ and $\\lambda_2 \\approx 0$)\n",
    "2. **Edge**: One eigenvalue is large and one is small ($\\lambda_1 \\gg \\lambda_2$ or $\\lambda_2 \\gg \\lambda_1$)\n",
    "3. **Corner**: Both eigenvalues are large ($\\lambda_1$ and $\\lambda_2$ are both large)\n",
    "\n",
    "The eigenvalues represent the principal curvatures of the local autocorrelation function:\n",
    "- $\\lambda_1$ corresponds to the direction of maximum intensity change\n",
    "- $\\lambda_2$ corresponds to the direction of minimum intensity change\n",
    "\n",
    "For a corner, intensity changes significantly in both directions, resulting in two large eigenvalues.\n",
    "\n",
    "### 4.6 Corner Response Function\n",
    "\n",
    "Computing eigenvalues is computationally expensive, so Harris proposed a corner response function:\n",
    "\n",
    "$$R = \\det(M) - k \\cdot \\text{trace}(M)^2$$\n",
    "\n",
    "Where:\n",
    "- $\\det(M) = \\lambda_1 \\lambda_2$\n",
    "- $\\text{trace}(M) = \\lambda_1 + \\lambda_2$\n",
    "- $k$ is an empirical constant (typically 0.04-0.06)\n",
    "\n",
    "The classification based on R is:\n",
    "- $R > 0$ and large: Corner\n",
    "- $R < 0$: Edge\n",
    "- $|R| \\approx 0$: Flat region\n",
    "\n",
    "### 4.7 Algorithm Steps\n",
    "\n",
    "1. Convert the image to grayscale\n",
    "2. Compute the x and y derivatives of the image ($I_x$ and $I_y$)\n",
    "3. Compute the products of derivatives for each pixel ($I_x^2$, $I_y^2$, $I_x I_y$)\n",
    "4. Apply Gaussian filtering to the products\n",
    "5. Compute the corner response function R\n",
    "6. Apply thresholding to find strong corners\n",
    "7. Apply non-maximum suppression to find local maxima\n",
    "\n",
    "## 5. Implementation in OpenCV\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image and convert to grayscale\n",
    "image = cv2.imread('image.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Convert to float32\n",
    "gray = np.float32(gray)\n",
    "\n",
    "# Apply Harris corner detection\n",
    "dst = cv2.cornerHarris(gray, blockSize=2, ksize=3, k=0.04)\n",
    "\n",
    "# Dilate to mark the corners\n",
    "dst = cv2.dilate(dst, None)\n",
    "\n",
    "# Threshold for optimal corner selection\n",
    "image[dst > 0.01 * dst.max()] = [0, 0, 255]  # Mark corners in red\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('Harris Corners', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "## 6. Advantages and Limitations\n",
    "\n",
    "### 6.1 Advantages\n",
    "- Rotation invariant: Performs well even if the image is rotated\n",
    "- Relatively simple to implement\n",
    "- Robust to moderate levels of noise\n",
    "- Good repeatability: Reliably detects the same corners across multiple images\n",
    "\n",
    "### 6.2 Limitations\n",
    "- Not scale invariant: Performance degrades with significant scale changes\n",
    "- Sensitive to noise in some scenarios\n",
    "- Parameter dependent: Results vary based on chosen parameters\n",
    "- Computationally intensive for large images\n",
    "\n",
    "## 7. Applications\n",
    "\n",
    "Harris Corner Detection is widely used in:\n",
    "1. **Feature Tracking**: Following the same point across a sequence of images\n",
    "2. **Image Matching**: Finding correspondences between different views\n",
    "3. **3D Reconstruction**: Building 3D models from multiple images\n",
    "4. **Object Recognition**: Identifying objects based on corner patterns\n",
    "5. **Camera Calibration**: Determining camera parameters\n",
    "6. **Image Stitching**: Creating panoramas by aligning multiple images\n",
    "\n",
    "## 8. Conclusion\n",
    "\n",
    "Edge and corner detection are fundamental techniques in computer vision. While edge detection identifies boundaries between regions, corner detection locates points where these boundaries meet, providing more distinctive and stable features. Harris Corner Detection, with its mathematical foundation in analyzing how image intensity changes in different directions, offers a robust approach for identifying corners in images, serving as the basis for many higher-level computer vision tasks."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
